{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    " \n",
    "langfuse = Langfuse()\n",
    "langfuse_prompt = langfuse.get_prompt(\"rag-base-prompt-with-context\", cache_ttl_seconds=0)\n",
    "print(langfuse_prompt.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_prompt = langfuse_prompt.get_langchain_prompt()\n",
    "online_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse_prompt.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "docs = WikipediaLoader(query=\"Artificial intelligence\", load_max_docs=2, doc_content_chars_max=1000).load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=300,chunk_overlap=30)\n",
    "documents=text_splitter.split_documents(docs)\n",
    "for doc in documents[:5]:\n",
    "    print(doc.page_content, \"\\n\")\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 2},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=langfuse_prompt.config[\"model\"], temperature=langfuse_prompt.config[\"temperature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(online_prompt)\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "from langfuse.decorators import langfuse_context\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "    session_id=\"langchain-test\",\n",
    "    user_id=\"kartik@gmail.com\",\n",
    "    metadata={\"is_notebook\": True},\n",
    "    tags=[\"lang_check\"]\n",
    ")\n",
    "# langfuse_handler = langfuse_context.get_current_langchain_handler()\n",
    "print(rag_chain.invoke(\"what is AI ?\", config={\"callbacks\": [langfuse_handler]}))\n",
    "\n",
    "# optional\n",
    "langfuse_handler.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based Evaluation\n",
    "- we can use available or a custom template\n",
    "- can run evaluations based on filter criterias\n",
    "- Finally we the scores are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate the query's different text languages and the generation on a continuous scale from 0 to 1. A generation can be considered correct (Score: 1) if the generation language is the same as the query language.\n",
    "\n",
    "Input:\n",
    "Query: com'è il tempo in India?\n",
    "Generation: The weather in India is hot and humid. Current dusty and partly cloudy conditions are expected to continue throughout the day.\n",
    "Score: 0\n",
    "Reasoning: The query was in Italian language but the generation was in English\n",
    "\n",
    "Input:\n",
    "Query: what is a galaxy?\n",
    "Generation: A galaxy is a cluster of stars. notre soleil est un début\n",
    "Score: 0.4\n",
    "Reasoning: The query was in English but the generation was partially in English and partially in French\n",
    "\n",
    "Input:\n",
    "Query: {{query}}\n",
    "Generation: {{generation}}\n",
    "\n",
    "Think step by step.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Score between 0 and 1\n",
    "Give a one word output of the query language detected\n",
    "lang_check\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langfuse_handler = CallbackHandler(\n",
    "    session_id=\"model-based-eval-check\",\n",
    "    user_id=\"kartik@gmail.com\",\n",
    "    metadata={\"is_notebook\": True},\n",
    "    tags = [\"lang_check\"]\n",
    ")\n",
    "rag_chain.invoke(\"cosa è AI ?\", config={\"callbacks\": [langfuse_handler]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
